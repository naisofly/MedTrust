{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"UTAustin-AIHealth/MedHallu\", \"pqa_labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (1000, 6)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MedHallu dataset human lablled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "Index(['Question', 'Knowledge', 'Ground Truth', 'Difficulty Level',\n",
      "       'Hallucinated Answer', 'Category of Hallucination'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Knowledge</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Difficulty Level</th>\n",
       "      <th>Hallucinated Answer</th>\n",
       "      <th>Category of Hallucination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
       "      <td>[Programmed cell death (PCD) is the regulated ...</td>\n",
       "      <td>Results depicted mitochondrial dynamics in viv...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Mitochondria regulate the formation of perfora...</td>\n",
       "      <td>Mechanism and Pathway Misattribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
       "      <td>[Assessment of visual acuity depends on the op...</td>\n",
       "      <td>Using the charts described, there was only a s...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Patients with strabismus amblyopia showed a si...</td>\n",
       "      <td>Incomplete Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
       "      <td>[Apparent life-threatening events in infants a...</td>\n",
       "      <td>\"Aquagenic maladies\" could be a pediatric form...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Syncope during bathing in infants is a manifes...</td>\n",
       "      <td>Misinterpretation of #Question#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are the long-term results of the transanal pul...</td>\n",
       "      <td>[The transanal endorectal pull-through (TERPT)...</td>\n",
       "      <td>Our long-term study showed significantly bette...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Both transanal and transabdominal pull-through...</td>\n",
       "      <td>Misinterpretation of #Question#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can tailored interventions increase mammograph...</td>\n",
       "      <td>[Telephone counseling and tailored print commu...</td>\n",
       "      <td>The effects of the intervention were most pron...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Tailored text messages were found to be as eff...</td>\n",
       "      <td>Incomplete Information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Do mitochondria play a role in remodelling lac...   \n",
       "1  Landolt C and snellen e acuity: differences in...   \n",
       "2  Syncope during bathing in infants, a pediatric...   \n",
       "3  Are the long-term results of the transanal pul...   \n",
       "4  Can tailored interventions increase mammograph...   \n",
       "\n",
       "                                           Knowledge  \\\n",
       "0  [Programmed cell death (PCD) is the regulated ...   \n",
       "1  [Assessment of visual acuity depends on the op...   \n",
       "2  [Apparent life-threatening events in infants a...   \n",
       "3  [The transanal endorectal pull-through (TERPT)...   \n",
       "4  [Telephone counseling and tailored print commu...   \n",
       "\n",
       "                                        Ground Truth Difficulty Level  \\\n",
       "0  Results depicted mitochondrial dynamics in viv...           medium   \n",
       "1  Using the charts described, there was only a s...             hard   \n",
       "2  \"Aquagenic maladies\" could be a pediatric form...             hard   \n",
       "3  Our long-term study showed significantly bette...             easy   \n",
       "4  The effects of the intervention were most pron...             hard   \n",
       "\n",
       "                                 Hallucinated Answer  \\\n",
       "0  Mitochondria regulate the formation of perfora...   \n",
       "1  Patients with strabismus amblyopia showed a si...   \n",
       "2  Syncope during bathing in infants is a manifes...   \n",
       "3  Both transanal and transabdominal pull-through...   \n",
       "4  Tailored text messages were found to be as eff...   \n",
       "\n",
       "              Category of Hallucination  \n",
       "0  Mechanism and Pathway Misattribution  \n",
       "1                Incomplete Information  \n",
       "2       Misinterpretation of #Question#  \n",
       "3       Misinterpretation of #Question#  \n",
       "4                Incomplete Information  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category of Hallucination\n",
       "Misinterpretation of #Question#            752\n",
       "Incomplete Information                     212\n",
       "Mechanism and Pathway Misattribution        33\n",
       "Methodological and Evidence Fabrication      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category of Hallucination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Difficulty Level\n",
       "hard      408\n",
       "medium    318\n",
       "easy      274\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Difficulty Level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goodfire\n",
    "GOODFIRE_API_KEY = os.getenv(\"GOODFIRE_API_KEY\")\n",
    "client = goodfire.Client(api_key=GOODFIRE_API_KEY)\n",
    "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 700, Test set size: 300\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(shuffled_df, test_size=0.3, random_state=42)\n",
    "print(f\"Training set size: {len(train_df)}, Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COMPUTE_SIZE = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using goodfire to get contrat features for hallucinated and non-hallucinated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hallucinated_features, hallucinated_features = client.features.contrast(\n",
    "    dataset_1=[\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is some relevant knowledge: {row['Knowledge']}\\n\\nQuestion: {row['Question']}\",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": row['Ground Truth']},\n",
    "        ]\n",
    "        for _,row in train_df[0:FEATURE_COMPUTE_SIZE].iterrows()\n",
    "    ],\n",
    "    dataset_2=[\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is some relevant knowledge: {row['Knowledge']}\\n\\nQuestion: {row['Question']}\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": f\"{row['Hallucinated Answer']}]\" \n",
    "            }\n",
    "        ]\n",
    "        for _,row in train_df[0:FEATURE_COMPUTE_SIZE].iterrows()\n",
    "    ],\n",
    "    model=variant,\n",
    "    top_k=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking features to get the most important ones based on query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_query = \"medical misinformation and factual errors in healthcare answers\"\n",
    "non_hallucination_query = \"accurate and factual medical information with proper evidence\"\n",
    "\n",
    "\n",
    "non_hallucinated_features = client.features.rerank(\n",
    "    features=non_hallucinated_features,\n",
    "    query=non_hallucination_query,\n",
    "    model=variant,\n",
    "    top_k=5\n",
    ")\n",
    "hallucinated_features = client.features.rerank(\n",
    "    features=hallucinated_features,\n",
    "    query=hallucination_query,\n",
    "    model=variant,\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureGroup([\n",
       "   0: \"Academic or technical results and findings being presented\",\n",
       "   1: \"The assistant should provide careful qualifications and disclaimers\",\n",
       "   2: \"Scientific methodology and analytical terminology\",\n",
       "   3: \"Evidence-based implementation and evaluation strategies\",\n",
       "   4: \"Scientific uncertainty and calls for more research\"\n",
       "])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_hallucinated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureGroup([\n",
       "   0: \"Statistical changes in risk levels in medical literature\",\n",
       "   1: \"Medical diagnostic relationships between diseases and symptoms\",\n",
       "   2: \"Potential hazards or negative outcomes in technical writing\",\n",
       "   3: \"The assistant is making incorrect statements with high confidence\",\n",
       "   4: \"Major medical journal names and citation formats\"\n",
       "])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucinated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureGroup([\n",
       "   0: \"Academic or technical results and findings being presented\",\n",
       "   1: \"The assistant should provide careful qualifications and disclaimers\",\n",
       "   2: \"Scientific methodology and analytical terminology\",\n",
       "   3: \"Evidence-based implementation and evaluation strategies\",\n",
       "   4: \"Scientific uncertainty and calls for more research\",\n",
       "   5: \"Statistical changes in risk levels in medical literature\",\n",
       "   6: \"Medical diagnostic relationships between diseases and symptoms\",\n",
       "   7: \"Potential hazards or negative outcomes in technical writing\",\n",
       "   8: \"The assistant is making incorrect statements with high confidence\",\n",
       "   9: \"Major medical journal names and citation formats\"\n",
       "])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_look_at = non_hallucinated_features | hallucinated_features\n",
    "features_to_look_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_client = goodfire.AsyncClient(api_key=GOODFIRE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.37it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.21it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "CLASSIFIER_FULL_SET_SIZE = 200\n",
    "\n",
    "async def _get_feature_acts_for_sample_class(\n",
    "    sample_class: pd.DataFrame,\n",
    "    features_to_use_for_classification: goodfire.FeatureGroup,\n",
    "    is_positive_class: bool,\n",
    "    k=100,\n",
    "    batch_size=10\n",
    "):\n",
    "    if k < len(features_to_use_for_classification):\n",
    "        raise ValueError(\n",
    "            \"k must be greater than the number of features to use for classification\"\n",
    "        )\n",
    "\n",
    "    samples = []\n",
    "    all_samples = sample_class[0:CLASSIFIER_FULL_SET_SIZE]\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(all_samples), batch_size):\n",
    "        batch = all_samples[i:i + batch_size]\n",
    "        tasks = []\n",
    "\n",
    "        for _, row in batch.iterrows():\n",
    "            tasks.append(\n",
    "                async_client.features.inspect(\n",
    "                    [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"Here is some relevant knowledge: {row['Knowledge']}\\n\\nQuestion: {row['Question']}\",\n",
    "                        },\n",
    "                        {\"role\": \"assistant\", \"content\": row['Ground Truth'] if is_positive_class else f\"{row['Hallucinated Answer']}]\"}\n",
    "\n",
    "                    ],\n",
    "                    model=variant,\n",
    "                    features=features_to_use_for_classification,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Process this batch\n",
    "        batch_results = await tqdm_asyncio.gather(*tasks)\n",
    "        for context in batch_results:\n",
    "            features = context.top(k=k)\n",
    "            samples.append(features)\n",
    "\n",
    "    return samples\n",
    "\n",
    "async def process_all_classes(dataset,start=0 , end=None):\n",
    "    classification_df = dataset[start:end]\n",
    "\n",
    "    non_hallucinated_class_features = await _get_feature_acts_for_sample_class(\n",
    "        classification_df, features_to_look_at, k=100, is_positive_class=True\n",
    "    )\n",
    "\n",
    "    hallucinated_class_features = await _get_feature_acts_for_sample_class(\n",
    "        classification_df, features_to_look_at, k=100, is_positive_class=False\n",
    "    )\n",
    "\n",
    "    return non_hallucinated_class_features, hallucinated_class_features\n",
    "\n",
    "\n",
    "non_hallucinated_class_features, hallucinated_class_features = await process_all_classes(train_df,start=FEATURE_COMPUTE_SIZE , end=FEATURE_COMPUTE_SIZE+CLASSIFIER_FULL_SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLASSIFIER_FULL_SET_SIZE =50\n",
    "\n",
    "non_hallucinated_test_class_features, hallucinated_test_class_features = await process_all_classes(test_df,start=0 , end=TEST_CLASSIFIER_FULL_SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class FeatureSearch:\n",
    "    \"\"\"A class for systematically searching through combinations of features to evaluate their predictive power.\"\"\"\n",
    "\n",
    "    def __init__(self, feature_group):\n",
    "        self.feature_group = feature_group\n",
    "\n",
    "    def grid(self, k_features_per_combo: int = 2):\n",
    "        \"\"\"Perform a grid search over all possible combinations of features.\n",
    "\n",
    "        Args:\n",
    "            k_features_per_combo (int): The number of features to include in each combination.\n",
    "\n",
    "        Returns:\n",
    "            list: All possible k-sized combinations of features from the feature group.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all possible combinations of features\n",
    "        return list(combinations(self.feature_group, k_features_per_combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn import tree\n",
    "# Now add a function to evaluate on test set\n",
    "def evaluate_on_test_set(model, combo):\n",
    "    # Helper function to extract feature activations - same as in training\n",
    "    def _select_feature_acts(combo, row):\n",
    "        output = []\n",
    "        for feature in combo:\n",
    "            for feature_act in row:\n",
    "                if feature_act.feature.uuid == feature.uuid:\n",
    "                    output.append(feature_act.activation)\n",
    "                    break\n",
    "        return output\n",
    "    \n",
    "    # Get test features\n",
    "    x_test_negative = [\n",
    "        _select_feature_acts(combo, row) for row in hallucinated_test_class_features\n",
    "    ]\n",
    "    x_test_positive = [\n",
    "        _select_feature_acts(combo, row) for row in non_hallucinated_test_class_features\n",
    "    ]\n",
    "    y_test_negative = [-1] * len(x_test_negative)\n",
    "    y_test_positive = [1] * len(x_test_positive)\n",
    "    \n",
    "    X_test = x_test_negative + x_test_positive\n",
    "    y_test = y_test_negative + y_test_positive\n",
    "    \n",
    "    # Make predictions\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "     # Calculate basic metrics\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds, average='weighted')\n",
    "    test_balanced_acc = balanced_accuracy_score(y_test, test_preds)\n",
    "    test_precision = precision_score(y_test, test_preds, average='weighted')\n",
    "    test_recall = recall_score(y_test, test_preds, average='weighted')\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, test_preds).ravel()\n",
    "        \n",
    "\n",
    "    #print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    return {\n",
    "        'accuracy': test_accuracy,\n",
    "        'f1_score': test_f1,\n",
    "        'balanced_accuracy': test_balanced_acc,\n",
    "        'precision': test_precision,\n",
    "        'recall': test_recall,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp\n",
    "    }\n",
    "\n",
    "# Update the find_best_combo function to use train/test split properly\n",
    "def find_best_combo(features, k_features_per_combo=2):\n",
    "    combos = FeatureSearch(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "    best_combo = None\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_test_metrics = None\n",
    "\n",
    "    for combo in tqdm.tqdm(combos):\n",
    "        # Helper function to extract feature activations\n",
    "        def _select_feature_acts(combo, row):\n",
    "            output = []\n",
    "            for feature in combo:\n",
    "                for feature_act in row:\n",
    "                    if feature_act.feature.uuid == feature.uuid:\n",
    "                        output.append(feature_act.activation)\n",
    "                        break\n",
    "            return output\n",
    "\n",
    "        # Train on training data\n",
    "        x_train_negative = [_select_feature_acts(combo, row) for row in hallucinated_class_features]\n",
    "        x_train_positive = [_select_feature_acts(combo, row) for row in non_hallucinated_class_features]\n",
    "        y_train_negative = [-1] * len(x_train_negative)\n",
    "        y_train_positive = [1] * len(x_train_positive)\n",
    "\n",
    "        X_train = x_train_negative + x_train_positive\n",
    "        y_train = y_train_negative + y_train_positive\n",
    "\n",
    "        # Create and train model\n",
    "        model = tree.DecisionTreeClassifier(\n",
    "            max_depth=len(combo), \n",
    "            min_samples_leaf=len(X_train) // 10, \n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_metrics = evaluate_on_test_set(model, combo)\n",
    "        \n",
    "        # Use test F1 score for selection\n",
    "        test_f1 = test_metrics['f1_score']\n",
    "        \n",
    "        if test_f1 > best_score:\n",
    "            best_score = test_f1\n",
    "            best_combo = combo\n",
    "            best_model = model\n",
    "            best_test_metrics = test_metrics\n",
    "\n",
    "    print(f\"Best combo test metrics: {best_test_metrics}\")\n",
    "    return best_combo, best_score, best_model\n",
    "\n",
    "\n",
    "\n",
    "best_combo_at_k = {}\n",
    "for i in range(3):\n",
    "    best_combo, best_score, best_model = find_best_combo(\n",
    "        features_to_look_at, k_features_per_combo=i + 1\n",
    "    )\n",
    "    print(i + 1, best_combo, best_score, best_model)\n",
    "    best_combo_at_k[i + 1] = (best_combo, best_score, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# The evaluate_on_test_set function can remain the same\n",
    "# ... existing code ...\n",
    "\n",
    "# Update the find_best_combo function to use RandomForest instead of Decision Tree\n",
    "def find_best_combo_random_forest(features, k_features_per_combo=2):\n",
    "    combos = FeatureSearch(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "    best_combo = None\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_test_metrics = None\n",
    "\n",
    "    for combo in tqdm.tqdm(combos):\n",
    "        # Helper function to extract feature activations\n",
    "        def _select_feature_acts(combo, row):\n",
    "            output = []\n",
    "            for feature in combo:\n",
    "                for feature_act in row:\n",
    "                    if feature_act.feature.uuid == feature.uuid:\n",
    "                        output.append(feature_act.activation)\n",
    "                        break\n",
    "            return output\n",
    "\n",
    "        # Train on training data\n",
    "        x_train_negative = [_select_feature_acts(combo, row) for row in hallucinated_class_features]\n",
    "        x_train_positive = [_select_feature_acts(combo, row) for row in non_hallucinated_class_features]\n",
    "        y_train_negative = [-1] * len(x_train_negative)\n",
    "        y_train_positive = [1] * len(x_train_positive)\n",
    "\n",
    "        X_train = x_train_negative + x_train_positive\n",
    "        y_train = y_train_negative + y_train_positive\n",
    "\n",
    "        # Create and train Random Forest model\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,  # Allow trees to grow fully\n",
    "            min_samples_leaf=len(X_train) // 20,  # Smaller leaf size for RF\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_metrics = evaluate_on_test_set(model, combo)\n",
    "        \n",
    "        # Use test F1 score for selection\n",
    "        test_f1 = test_metrics['f1_score']\n",
    "        \n",
    "        if test_f1 > best_score:\n",
    "            best_score = test_f1\n",
    "            best_combo = combo\n",
    "            best_model = model\n",
    "            best_test_metrics = test_metrics\n",
    "\n",
    "    print(f\"Best combo test metrics: {best_test_metrics}\")\n",
    "    return best_combo, best_score, best_model\n",
    "\n",
    "# Function to visualize feature importance\n",
    "def plot_feature_importance(model, feature_combo):\n",
    "    feature_labels = [f.label for f in feature_combo]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(importances)\n",
    "    \n",
    "    plt.figure(figsize=(10, len(feature_combo) * 0.5))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [feature_labels[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Also print numerical values\n",
    "    for i in indices:\n",
    "        print(f\"{feature_labels[i]}: {importances[i]:.4f}\")\n",
    "\n",
    "# Now run the search with different numbers of features\n",
    "best_combo_at_k = {}\n",
    "for i in range(3):\n",
    "    print(f\"\\nRunning search with {i+1} features per combo...\")\n",
    "    best_combo, best_score, best_model = find_best_combo(\n",
    "        features_to_look_at, k_features_per_combo=i + 1\n",
    "    )\n",
    "    print(f\"Best combo ({i+1} features): {[f.label for f in best_combo]}\")\n",
    "    print(f\"Best test F1 score: {best_score}\")\n",
    "    best_combo_at_k[i + 1] = (best_combo, best_score, best_model)\n",
    "    \n",
    "    # Plot feature importance for this model\n",
    "    print(\"\\nFeature importance:\")\n",
    "    plot_feature_importance(best_model, best_combo)\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_combo_rf(features, k_features_per_combo=3):\n",
    "    \"\"\"Find the best combination of features using Random Forest.\"\"\"\n",
    "    combos = FeatureSearch(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "    best_combo = None\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_test_metrics = None\n",
    "\n",
    "    for combo in tqdm.tqdm(combos):\n",
    "        # Helper function to extract feature activations\n",
    "        def _select_feature_acts(combo, row):\n",
    "            output = []\n",
    "            for feature in combo:\n",
    "                for feature_act in row:\n",
    "                    if feature_act.feature.uuid == feature.uuid:\n",
    "                        output.append(feature_act.activation)\n",
    "                        break\n",
    "            return output\n",
    "\n",
    "        # Train on training data\n",
    "        x_train_negative = [_select_feature_acts(combo, row) for row in hallucinated_class_features]\n",
    "        x_train_positive = [_select_feature_acts(combo, row) for row in non_hallucinated_class_features]\n",
    "        y_train_negative = [-1] * len(x_train_negative)\n",
    "        y_train_positive = [1] * len(x_train_positive)\n",
    "\n",
    "        X_train = x_train_negative + x_train_positive\n",
    "        y_train = y_train_negative + y_train_positive\n",
    "\n",
    "        # Create and train Random Forest model\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=len(X_train) // 20,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_metrics = evaluate_on_test_set(model, combo)\n",
    "        test_f1 = test_metrics['f1_score']\n",
    "        \n",
    "        if test_f1 > best_score:\n",
    "            best_score = test_f1\n",
    "            best_combo = combo\n",
    "            best_model = model\n",
    "            best_test_metrics = test_metrics\n",
    "\n",
    "    print(f\"Best combo test metrics: {best_test_metrics}\")\n",
    "    return best_combo, best_score, best_model\n",
    "\n",
    "best_combo_at_k = {}\n",
    "for i in range(3):\n",
    "    best_combo, best_score, best_model = find_best_combo_rf(\n",
    "        features_to_look_at, k_features_per_combo=i + 1\n",
    "    )\n",
    "    print(i + 1, best_combo, best_score, best_model)\n",
    "    best_combo_at_k[i + 1] = (best_combo, best_score, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
